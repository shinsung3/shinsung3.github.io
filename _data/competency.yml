- main: Health & Wellness 전문관 <mark> Lime 플랫폼 신규 구축</mark>
  title: 확장 가능한 콘텐츠 구조 설계를 통한 신규 전문관 플랫폼 구축
  problem: |
   * 메인 페이지 성능 저하는 전문관 이탈률을 높일 수 있어 가장 치명적인 리스크였음
    * 신규 전문관은 상품, 리뷰, 레시피, 푸드톡, 배너 등 <mark>서로 다른 콘텐츠를 한 화면에서 한 번에 조회해야 하는 요구사항</mark>이 있었음
    * 기존 구조대로라면 여러 테이블을 조인하거나 각 도메인 API를 병렬 호출해야 하므로, 콘텐츠 타입이 늘어날수록 <mark>성능 저하</mark>와 <mark>쿼리 복잡도 증가</mark>가 불가피한 구조적 한계 발생
   * 기술 외에도 조직 내 최초 목적형 스쿼드 구조로, 짧은 기간 내 신규 전문관을 안정적으로 구축해야 하는 상황
  solution: | 
   * 조회 성능과 확장성을 보장하기 위해 상품/리뷰/푸드톡/배너/매거진/카드뉴스/ELT 등을 조인 없이 단일 조회로 전시할 수 있는 통합 전시 테이블 구조 설계
    * BO에서 콘텐츠 등록 시 각 콘텐츠의 원본 PK, 타입, 카드 UI 정보, 전시 순서를 모두 전시 전용 테이블에 저장하여 화면 구성 정보를 사전 확정
    * 전시 API는 복잡한 조인 없이 LIME_CONTENTS 단일 테이블만 조회하여 <mark>전시 구성을 즉시 렌더링</mark>할 수 있도록 구성
    * 콘텐츠 타입이 증가해도 테이블 스키마 변경 없이 전시 전용 API만 추가하면 확장 가능한 구조로 설계
  competency: |
    신규 Health & Wellness 전문관을 <mark>독립된 전시 플랫폼 형태로 안정적으로 구축</mark>할 수 있었습니다. 콘텐츠 타입이 추가되더라도 쿼리 구조 변경 없이 확장 가능한 구조를 마련해, 숏폼 등 신규 도메인 확장 시 <mark>추가 개발 비용을 크게 절감</mark>할 수 있었습니다. 현재 Phase 2를 진행하며 스쿼드 운영 과정에서 드러난 운영진의 불편 요소를 분석하고, <mark>운영 효율화</mark>를 위한 콘텐츠 직접 설정 및 Google Vision AI API 기반 테마 설정 기능을 추가 개발 중입니다.

- main: <mark>장바구니 시스템 클라우드 전환</mark> 및 구매 전 추천 페이지 개선
  title: 레거시 장바구니 구조 개선과 기술 스택 현대화를 통한 구매 경험 향상
  problem: |
   * 기존 장바구니 시스템은 Java + Spring + JSP 기반의 레거시 구조
   * 작은 기능 변경도 전체 안정성에 영향, 테스트 비용 증가
   * 클라우드 전환 및 서비스 확장을 고려했을 때, 확장 대비가 어려운 기술 스택(JDK 1.8, JSP)
  solution: | 
   * 레거시 개편 프로젝트를 계기로 구조를 재설계 : <mark>Spring Boot + Vue.js 기반 구조</mark>로 점진적 전환
     * JDK 8 → 21 업그레이드 진행
     * 프론트/백엔드 역할 분리를 위한 Vue.js 도입 → 화면 로직과 서버 도메인 로직 분리로 변경 영향 최소화
   * <mark>헥사고날 아키텍처 적용 (WHY)</mark>
    * 클라우드 전환 후에도 외부 연동 변화가 잦아질 것이 예상되었기 때문에 도메인을 크게 전시/주문으로 나누고 화면/서비스/DB의 의존을 분리
   * 장바구니/주문서 사이에 <mark>구매 전 추천 페이지</mark> 재설계
    * <mark>(Before)</mark>DB를 거쳐 상품 번호 → 상세 조회 방식을 <mark>(After)</mark>OpenSearch 로 이관해 상품 번호 기반 즉시 조회 → 속도 개선
  competency: |
   이번 개편에서는 기능 추가보다 <mark>장바구니 도메인을 어떻게 보호할 것인가</mark>를 가장 중요하게 보았습니다. <mark>헥사고날 아키텍처</mark>를 적용해 핵심 도메인과 의존성을 분리하려고 했고 이로써 장바구니 안정성에 영향을 주지 않도록 설계했습니다. 또한 Spring Boot, Vue.js, JDK 21 기반으로 점진적 전환을 병행하며 <mark>구조적 안정성과 기술적 확장성</mark>을 확보할 수 있었습니다.  이 경험을 통해 저는 레거시를 이해하고, <mark>도메인을 중심으로 구조를 재설계</mark>할 수 있는 개발자라는 역량을 갖추게 되었습니다.

- main: <mark>업무 자동화</mark>를 통한 QA 이슈 대응 체계 개선
  title: n8n 기반 AI Agent를 활용한 QA 이슈 알림봇 구축
  problem: |
   * QA 과정에서 Jira 이슈 생성, 상태 변경, 댓글 멘션 등이 각 담당자가 직접하지 않으면 알 수 있는 방법 없음
   * 특히 QA담당자가 이슈 상태를 바로 <mark>인지하지 못해 대응이 지연되는 경우</mark>가 반복적으로 발생
   * 2개의 프로젝트를 진행하면서 QA 대응 과정의 효율을 개선할 필요성을 느낌
  solution: |
   * <mark>n8n 기반 AI Agent</mark>에 Jira Webhook을 이용한 정보 수집과 자동 처리하는 구조를 설계
   * 이슈 생성, 상태 변경, 댓글 멘션 발생 시 필요한 정보만 추출해 Slack으로 실시간 알림을 전송하도록 구현
   * AI Agent를 연동해 이슈 설명, 변경 내역, 댓글을 통해 <mark>다음 행동의 필요성 여부를 판단</mark>하고 안내하여 담당자가 빠르게 상황을 이해할 수 있도록 개선
  competency: |
   저는 다른 팀과의 커뮤니케이션 과정에서 발생하는 비효율을 개발을 통해 개선할 수 있다고 생각합니다. <mark>QA 이슈를 빠르게 인지하고 정확하게 공유하는 구조</mark>를 만드는 것이 핵심이었습니다. n8n과 AI Agent를 활용해 기존 업무 흐름을 자동화함으로써 개발과 QA 모두가 본질적인 문제 해결에 집중할 수 있는 환경을 만들고자 했습니다.

- main: 불필요한 <mark>수기 반복작업</mark> 제거  (연간 500건 → 0건)
  title: Back Office > 전시 관리 수기 등록 구조 개선
  problem: |
   * 전시 페이지는 모듈 조합형 구조였으나, 기획자가 조합을 변경할 때마다 개발자가 수기로 DB insert를 해야 하는 구조
   * 이로 인해 운영 기준 연간 500건 이상의 테스트/운영 insert 작업이 반복 발생했고, 개발자, 기획자 모두에게 불필요한 비용이 발생
  solution: | 
   * 전시 카테고리 페이지와 테마 페이지에서 구조적 분리가 되지 않았던 부분을 분리하여 저장하도록 개선
   * Back Office에서 같은 모듈이라도 페이지 유형을 선택해 등록할 수 있도록 구조를 변경
  competency: |
   저는 문제를 처리하기보다 <mark>반복을 만드는 구조 자체를 제거</mark>하는 데 집중합니다. 운영 중 자연스럽게 드러나는 <mark>비효율을 자발적으로 발견</mark>하고 구조 개선으로 연결해 <mark>조직 전체의 생산성</mark>을 높이고자했습니다.

- main: <mark>사전 장애 방지</mark>를 위한 Crema API 연동 <mark>구조 전면 개선</mark>
  title: 인테페이스 히스토리 테이블 데이터 폭증으로 인한 잠재 장애 사전 대응
  problem: |
   * <mark>최초 문제점 - 2021년</mark> : EQL 리뷰 API를 Crema로 전환하면서 인터페이스 히스토리 테이블에 데이터가 과도하게 누적되기 시작함
    * EQL 상품, 주문정보, 주문상세 정보에서 月 1,000만 건 데이터 누적 발생 (그 외 데이터까지 합친다면 1,100만 초과)
   * <mark>추가 문제점 - 2024년</mark> : H패션몰에도 리뷰가 크리마로 변경되면 인터페이스 히스토리 내 테이블 로그 적재량이 약 2배 증가
    * 테이블스페이스 한계로 인해 서비스는 정상 동작하나 DB에는 저장되지 않는 상태가 발생할 수 있는 잠재 장애 구조로 판단
  solution: | 
   * Crema 측과 직접 협업하여 단건 전송 구조는 양측 모두에 부하를 유발하는 구조임을 근거 기반으로 공유하며 개선을 제안
    * 그 결과 크리마 v2가 베타 버전으로 출시되어 가장 문제가 되었던 것들부터 순차적으로 List 형태로 데이터를 전송할 수 있도록 변경
    * EQL과 H패션몰의 다른 정책에도 불구하고 동일하게 쓰고 있던 배치 부분을 조건에 따라서 분기 처리 (EQL은 배송중일때 데이터전송, H패션몰은 배송완료일때 데이터전송)
    * 개당 20개~50개를 전달할 수 있도록 정책을 변경하였고, 상품을 최초로 시작하여 주문정보와 주문상세 & 클레임 정보에 관련된 SQL, 배치, interface 부분을 모두 수정
    * H패션몰 Crema 연동 이후의 성능과 안정성 확보를 위해 전체 개선 작업을 주도적으로 수행
    * H패션몰 기준
     * 주문 정보 : __36만 건 → 1만건__ (月 97% 감소)
     * 주문 상세 및 클레임 정보 : __67만 건 → 8천 건__ (月 98% 감소)
     * 상품 정보 : __3만 건 → 2천 건__ __(月 94% 감소)__
    * EQL 기준
     * 주문 정보 : __242만 건 → 4.8만건__ (月 98% 감소)
     * 주문 상세 및 클레임 정보 : __253만 건 → 5만 건__ (月 98% 감소)
     * 상품 정보 : __554만 건 → 11만 건__ __(月 98% 감소)__
  competency: |
   장애는 발생 이후도 중요하지만 장애로 이어질 구조를 사전에 제거하는 것이 더 중요하다고 생각합니다. 운영 중 누적되는 로그와 데이터의 흐름을 보고 <mark>잠재 장애 요소</mark>를 <mark>선제적으로 식별하고</mark> 기존 시스템이라도 필요하다면 부분 개선에 그치지 않고, 장애 가능성을 근본적으로 제거하는 방향으로 구조를 재설계해 안정성을 확보해 왔습니다.
